---
title: "Bayesian Non-stationary Linear Bandits for Large-Scale Recommender Systems"
type: Preprint
collection: publications
permalink: /publication/2023-07-24-bcmabrp
excerpt: 'Utilizing random projections to apply an MAB-algorithm to a recommender system scenario, where 
    the data is high-dimensional and user preferences change over time.'
date: 2023-07-24
paperurl: 'https://arxiv.org/abs/2202.03167'
paperurldescription: 'Access the paper'
codeurl: https://github.com/saeedghoorchian/D-LinTS-RP
authors: 'Saeed Ghoorchian, **Evgenii Kortukov**, Setareh Maghsudi'
venue: 'arXiv'
citation: 'Ghoorchian, S., Kortukov, E., & Maghsudi, S. (2023). Bayesian Non-stationary Linear Bandits for Large-Scale Recommender Systems. arXiv preprint arXiv:2202.03167.'
bibtex: "@misc{ghoorchian2023bayesian, <br>
      title={Bayesian Non-stationary Linear Bandits for Large-Scale Recommender Systems}, <br>
      author={Saeed Ghoorchian and Evgenii Kortukov and Setareh Maghsudi}, <br>
      year={2023}, <br>
      eprint={2202.03167}, <br>
      archivePrefix={arXiv}, <br>
      primaryClass={cs.LG} <br>
}"
---
Taking advantage of contextual information can potentially boost the performance of recommender systems. In the era of big data, such side information often has several dimensions. Thus, developing decision-making algorithms to cope with such a high-dimensional context in real time is essential. That is specifically challenging when the decision-maker has a variety of items to recommend. In addition, changes in items' popularity or users' preferences can hinder the performance of the deployed recommender system due to a lack of robustness to distribution shifts in the environment. In this paper, we build upon the linear contextual multi-armed bandit framework to address this problem. We develop a decision-making policy for a linear bandit problem with high-dimensional feature vectors, a large set of arms, and non-stationary reward-generating processes. Our Thompson sampling-based policy reduces the dimension of feature vectors using random projection and uses exponentially increasing weights to decrease the influence of past observations with time. Our proposed recommender system employs this policy to learn the users' item preferences online while minimizing runtime. We prove a regret bound that scales as a factor of the reduced dimension instead of the original one. To evaluate our proposed recommender system numerically, we apply it to three real-world datasets. The theoretical and numerical results demonstrate the effectiveness of our proposed algorithm in making a trade-off between computational complexity and regret performance compared to the state-of-the-art.

[<i class="fa fa-fw fa-book" aria-hidden="true"></i>Full paper](https://arxiv.org/abs/2202.03167) &nbsp;&nbsp;
[<i class="fa fa-fw fa-globe" aria-hidden="true"></i>Code](https://github.com/saeedghoorchian/D-LinTS-RP)

