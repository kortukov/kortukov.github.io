---
title: "Non-Stationary Linear Bandits With Dimensionality Reduction for Large-Scale Recommender Systems"
type: Journal
collection: publications
permalink: /publication/2023-07-24-bcmabrp
excerpt: 'Utilizing random projections to apply an MAB-algorithm to a recommender system scenario, where 
    the data is high-dimensional and user preferences change over time.'
date: 2023-07-24
paperurl: 'https://ieeexplore.ieee.org/document/10494875'
codeurl: https://github.com/saeedghoorchian/D-LinTS-RP
authors: 'Saeed Ghoorchian, **Evgenii Kortukov**, Setareh Maghsudi'
venue: 'IEEE Open Journal of Signal Processing'
bibtex: "@ARTICLE{10494875, <br>
  author={Ghoorchian, Saeed and Kortukov, Evgenii and Maghsudi, Setareh}, <br>
  journal={IEEE Open Journal of Signal Processing},  <br>
  title={Non-Stationary Linear Bandits With Dimensionality Reduction for Large-Scale Recommender Systems},  <br>
  year={2024}, <br>
  volume={5}, <br>
  number={}, <br>
  pages={548-558}, <br>
  keywords={Vectors;Recommender systems;Decision making;Runtime;Signal processing algorithms;Covariance matrices;Robustness;Decision-making;multi-armed bandit;non-stationary environment;online learning;recommender systems}, <br>
  doi={10.1109/OJSP.2024.3386490} <br>
  }"
---
Taking advantage of contextual information can potentially boost the performance of recommender systems. In the era of big data, such side information often has several dimensions. Thus, developing decision-making algorithms to cope with such a high-dimensional context in real time is essential. That is specifically challenging when the decision-maker has a variety of items to recommend. In addition, changes in items' popularity or users' preferences can hinder the performance of the deployed recommender system due to a lack of robustness to distribution shifts in the environment. In this paper, we build upon the linear contextual multi-armed bandit framework to address this problem. We develop a decision-making policy for a linear bandit problem with high-dimensional feature vectors, a large set of arms, and non-stationary reward-generating processes. Our Thompson sampling-based policy reduces the dimension of feature vectors using random projection and uses exponentially increasing weights to decrease the influence of past observations with time. Our proposed recommender system employs this policy to learn the users' item preferences online while minimizing runtime. We prove a regret bound that scales as a factor of the reduced dimension instead of the original one. To evaluate our proposed recommender system numerically, we apply it to three real-world datasets. The theoretical and numerical results demonstrate the effectiveness of our proposed algorithm in making a trade-off between computational complexity and regret performance compared to the state-of-the-art.

[<i class="fa fa-fw fa-book" aria-hidden="true"></i>Full paper](https://ieeexplore.ieee.org/document/10494875) &nbsp;&nbsp;
[<i class="fa fa-fw fa-globe" aria-hidden="true"></i>Code](https://github.com/saeedghoorchian/D-LinTS-RP)

